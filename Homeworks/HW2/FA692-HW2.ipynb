{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accessible-broadway",
   "metadata": {},
   "source": [
    "# FA692 Homework 2\n",
    "# Due: Wednesday, March 29 @ 11:59PM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aware-spouse",
   "metadata": {},
   "source": [
    "Name: Ryan Shea\n",
    "\n",
    "Date: March 28, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fundamental-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set seed of random number generator\n",
    "CWID = 10445281 #Place here your Campus wide ID number, this will personalize\n",
    "#your results, but still maintain the reproduceable nature of using seeds.\n",
    "#If you ever need to reset the seed in this assignment, use this as your seed\n",
    "#Papers that use -1 as this CWID variable will earn 0's so make sure you change\n",
    "#this value before you submit your work.\n",
    "personal = CWID % 10000\n",
    "np.random.seed(personal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-rebound",
   "metadata": {},
   "source": [
    "## Question 1 (10pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-shoulder",
   "metadata": {},
   "source": [
    "### Question 1.1\n",
    "Use the `yfinance` package (or other method of your choice) to obtain the daily adjusted close prices for the S&P500 (`SPY`) from January 1, 2023 to March 15, 2023.  You should inspect the dates for your data to make sure you are including everything appropriately.  Create a data frame (or array) of the daily log returns of this stock; you may concatenate this to your price data.  Use the `print` command to display your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ae435c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "             Adj Close       log\n",
      "Date                            \n",
      "2023-01-04  382.300964  0.007691\n",
      "2023-01-05  377.937592 -0.011479\n",
      "2023-01-06  386.604492  0.022673\n",
      "2023-01-09  386.385345 -0.000567\n",
      "2023-01-10  389.095001  0.006988\n",
      "2023-01-11  394.016235  0.012569\n",
      "2023-01-12  395.450745  0.003634\n",
      "2023-01-13  396.984894  0.003872\n",
      "2023-01-17  396.257660 -0.001834\n",
      "2023-01-18  390.001556 -0.015914\n",
      "2023-01-19  387.162415 -0.007306\n",
      "2023-01-20  394.374878  0.018458\n",
      "2023-01-23  399.106812  0.011927\n",
      "2023-01-24  398.678436 -0.001074\n",
      "2023-01-25  398.827881  0.000375\n",
      "2023-01-26  403.211151  0.010930\n",
      "2023-01-27  404.137604  0.002295\n",
      "2023-01-30  399.066956 -0.012626\n",
      "2023-01-31  404.934570  0.014596\n",
      "2023-02-01  409.238129  0.010572\n",
      "2023-02-02  415.195404  0.014452\n",
      "2023-02-03  410.782257 -0.010686\n",
      "2023-02-06  408.271820 -0.006130\n",
      "2023-02-07  413.611450  0.012994\n",
      "2023-02-08  409.088715 -0.010995\n",
      "2023-02-09  405.542236 -0.008707\n",
      "2023-02-10  406.488647  0.002331\n",
      "2023-02-13  411.260406  0.011671\n",
      "2023-02-14  411.071167 -0.000460\n",
      "2023-02-15  412.406067  0.003242\n",
      "2023-02-16  406.727722 -0.013864\n",
      "2023-02-17  405.711609 -0.002501\n",
      "2023-02-21  397.572662 -0.020265\n",
      "2023-02-22  397.024750 -0.001379\n",
      "2023-02-23  399.136688  0.005305\n",
      "2023-02-24  394.872955 -0.010740\n",
      "2023-02-27  396.217834  0.003400\n",
      "2023-02-28  394.753418 -0.003703\n",
      "2023-03-01  393.239197 -0.003843\n",
      "2023-03-02  396.297516  0.007747\n",
      "2023-03-03  402.653259  0.015911\n",
      "2023-03-06  402.932220  0.000693\n",
      "2023-03-07  396.755768 -0.015447\n",
      "2023-03-08  397.403320  0.001631\n",
      "2023-03-09  390.071289 -0.018622\n",
      "2023-03-10  384.442780 -0.014535\n",
      "2023-03-13  383.894836 -0.001426\n",
      "2023-03-14  390.240662  0.016395\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here\n",
    "import yfinance as yf\n",
    "\n",
    "spy = yf.download('SPY', start='2023-01-01', end='2023-03-15')\n",
    "\n",
    "spy['log'] = np.log(spy['Adj Close'] / spy['Adj Close'].shift(1))\n",
    "spy = spy[['Adj Close', 'log']].dropna()\n",
    "print(spy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce529190",
   "metadata": {},
   "source": [
    "## Question 2 (40pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-range",
   "metadata": {},
   "source": [
    "### Question 2.1\n",
    "Scrape data from the Bloomberg `@business` Twitter account from January 1, 2023 to March 15, 2023. Save this data to a Data Frame with time stamps. Additionally, save all the collected data to a text file with time stamps. You will need to submit the text file along with your work (-5 points if not submitted).\n",
    "\n",
    "Note: Bloomberg tweets sometimes include the pipe \"|\". I recomment using tilde \"~\" as a delimiter instead.\n",
    "\n",
    "Hint: Because saving the tweets can take a long time, you can comment that code out before exporting to pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "invisible-understanding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n",
    "import snscrape.modules.twitter as tw\n",
    "\n",
    "# f = open('business.txt', 'w', encoding='utf-8')\n",
    "\n",
    "# for tweet in tw.TwitterSearchScraper(query=\"(from:business) since:2023-01-01 until:2023-03-15\").get_items():\n",
    "#     date_str = tweet.date.strftime(\"%Y-%m-%d %H:%M:%S%z\")\n",
    "#     date_str = date_str[:-2] + \":\" + date_str[-2:]\n",
    "#     #f.write(date_str + \"|\" + tweet.content + \"\\n\")\n",
    "#     f.write(date_str + \"~\" + tweet.rawContent + \"\\n\")\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21d958d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-14 19:40:29-04:00</td>\n",
       "      <td>One Japanese fintech firm is making it compuls...</td>\n",
       "      <td>2023-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-14 19:40:29-04:00</td>\n",
       "      <td>An unlikely startup guru has emerged in Japan,...</td>\n",
       "      <td>2023-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-14 19:35:41-04:00</td>\n",
       "      <td>Some US cities are late in making financial di...</td>\n",
       "      <td>2023-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-14 19:31:07-04:00</td>\n",
       "      <td>The shipping industry is looking to rethink ev...</td>\n",
       "      <td>2023-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-14 19:25:09-04:00</td>\n",
       "      <td>A biotech wants to cut fashion waste by using ...</td>\n",
       "      <td>2023-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26813</th>\n",
       "      <td>2022-12-31 19:00:09-05:00</td>\n",
       "      <td>Toymakers have found a new group of customers:...</td>\n",
       "      <td>2022-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26814</th>\n",
       "      <td>2022-12-31 19:00:09-05:00</td>\n",
       "      <td>Belarusian hackers and dissidents determined t...</td>\n",
       "      <td>2022-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26815</th>\n",
       "      <td>2022-12-31 19:00:09-05:00</td>\n",
       "      <td>Landlords are taking out millions in loans to ...</td>\n",
       "      <td>2022-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26816</th>\n",
       "      <td>2022-12-31 19:00:09-05:00</td>\n",
       "      <td>It took a pandemic to make a dent in US inequa...</td>\n",
       "      <td>2022-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26817</th>\n",
       "      <td>2022-12-31 19:00:08-05:00</td>\n",
       "      <td>A planned train line in Mexico is billions ove...</td>\n",
       "      <td>2022-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26818 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Time  \\\n",
       "0     2023-03-14 19:40:29-04:00   \n",
       "1     2023-03-14 19:40:29-04:00   \n",
       "2     2023-03-14 19:35:41-04:00   \n",
       "3     2023-03-14 19:31:07-04:00   \n",
       "4     2023-03-14 19:25:09-04:00   \n",
       "...                         ...   \n",
       "26813 2022-12-31 19:00:09-05:00   \n",
       "26814 2022-12-31 19:00:09-05:00   \n",
       "26815 2022-12-31 19:00:09-05:00   \n",
       "26816 2022-12-31 19:00:09-05:00   \n",
       "26817 2022-12-31 19:00:08-05:00   \n",
       "\n",
       "                                                   Tweet        Date  \n",
       "0      One Japanese fintech firm is making it compuls...  2023-03-14  \n",
       "1      An unlikely startup guru has emerged in Japan,...  2023-03-14  \n",
       "2      Some US cities are late in making financial di...  2023-03-14  \n",
       "3      The shipping industry is looking to rethink ev...  2023-03-14  \n",
       "4      A biotech wants to cut fashion waste by using ...  2023-03-14  \n",
       "...                                                  ...         ...  \n",
       "26813  Toymakers have found a new group of customers:...  2022-12-31  \n",
       "26814  Belarusian hackers and dissidents determined t...  2022-12-31  \n",
       "26815  Landlords are taking out millions in loans to ...  2022-12-31  \n",
       "26816  It took a pandemic to make a dent in US inequa...  2022-12-31  \n",
       "26817  A planned train line in Mexico is billions ove...  2022-12-31  \n",
       "\n",
       "[26818 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "import pytz\n",
    "\n",
    "business = []\n",
    "dates = []\n",
    "f = open('business.txt', 'r', encoding='utf-8')\n",
    "\n",
    "for l in f:\n",
    "    line = l.split('~')\n",
    "    date_str = line[0]\n",
    "    try:\n",
    "        date_time = dt.fromisoformat(date_str)\n",
    "        date_time = date_time.astimezone(pytz.timezone(\"US/Eastern\"))\n",
    "        line[0] = date_time\n",
    "        line[1] = line[1][:-1]\n",
    "        business.append(line)\n",
    "        dates.append(date_time.date())\n",
    "    except:\n",
    "        business[-1][1] += \" \"+l[:-1]\n",
    "f.close()\n",
    "\n",
    "business = pd.DataFrame(business, columns=['Time', 'Tweet'])\n",
    "business['Date'] = dates\n",
    "\n",
    "business"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f054e182",
   "metadata": {},
   "source": [
    "### Question 2.2\n",
    "Using your favorite sentiment analyzer (e.g., `vaderSentiment`), find the average sentiment for the headlines on each date that data was collected. Concatenate this sentiment score to your data frame of log returns. Use the `print` command to display your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a95df69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Adj Close       log  Sentiment\n",
      "Date                                       \n",
      "2023-01-04  382.300964  0.007691  -0.010883\n",
      "2023-01-05  377.937592 -0.011479  -0.032084\n",
      "2023-01-06  386.604492  0.022673  -0.001990\n",
      "2023-01-09  386.385345 -0.000567   0.048762\n",
      "2023-01-10  389.095001  0.006988  -0.051226\n",
      "2023-01-11  394.016235  0.012569  -0.006794\n",
      "2023-01-12  395.450745  0.003634   0.012535\n",
      "2023-01-13  396.984894  0.003872  -0.017501\n",
      "2023-01-17  396.257660 -0.001834   0.013547\n",
      "2023-01-18  390.001556 -0.015914  -0.002899\n",
      "2023-01-19  387.162415 -0.007306  -0.019422\n",
      "2023-01-20  394.374878  0.018458  -0.052442\n",
      "2023-01-23  399.106812  0.011927   0.030476\n",
      "2023-01-24  398.678436 -0.001074  -0.031936\n",
      "2023-01-25  398.827881  0.000375  -0.036038\n",
      "2023-01-26  403.211151  0.010930  -0.000502\n",
      "2023-01-27  404.137604  0.002295   0.011412\n",
      "2023-01-30  399.066956 -0.012626   0.009724\n",
      "2023-01-31  404.934570  0.014596   0.018422\n",
      "2023-02-01  409.238129  0.010572   0.052543\n",
      "2023-02-02  415.195404  0.014452   0.040621\n",
      "2023-02-03  410.782257 -0.010686  -0.029209\n",
      "2023-02-06  408.271820 -0.006130  -0.006613\n",
      "2023-02-07  413.611450  0.012994  -0.010283\n",
      "2023-02-08  409.088715 -0.010995   0.030015\n",
      "2023-02-09  405.542236 -0.008707   0.025923\n",
      "2023-02-10  406.488647  0.002331   0.049027\n",
      "2023-02-13  411.260406  0.011671   0.037702\n",
      "2023-02-14  411.071167 -0.000460   0.045768\n",
      "2023-02-15  412.406067  0.003242  -0.009137\n",
      "2023-02-16  406.727722 -0.013864   0.033467\n",
      "2023-02-17  405.711609 -0.002501   0.001133\n",
      "2023-02-21  397.572662 -0.020265   0.040426\n",
      "2023-02-22  397.024750 -0.001379   0.037188\n",
      "2023-02-23  399.136688  0.005305  -0.003498\n",
      "2023-02-24  394.872955 -0.010740  -0.021110\n",
      "2023-02-27  396.217834  0.003400   0.018866\n",
      "2023-02-28  394.753418 -0.003703  -0.011442\n",
      "2023-03-01  393.239197 -0.003843   0.061795\n",
      "2023-03-02  396.297516  0.007747  -0.012462\n",
      "2023-03-03  402.653259  0.015911   0.024269\n",
      "2023-03-06  402.932220  0.000693   0.027701\n",
      "2023-03-07  396.755768 -0.015447   0.026721\n",
      "2023-03-08  397.403320  0.001631   0.052365\n",
      "2023-03-09  390.071289 -0.018622  -0.001680\n",
      "2023-03-10  384.442780 -0.014535  -0.054424\n",
      "2023-03-13  383.894836 -0.001426  -0.098203\n",
      "2023-03-14  390.240662  0.016395  -0.032399\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sentiment = []\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for tweet in business.Tweet:\n",
    "    vs = analyzer.polarity_scores(tweet)\n",
    "    sentiment.append(vs[\"compound\"])\n",
    "\n",
    "business['Sentiment'] = sentiment\n",
    "\n",
    "spy['Sentiment'] = business.pivot_table(index='Date', values='Sentiment', aggfunc='mean')\n",
    "print(spy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-tiger",
   "metadata": {},
   "source": [
    "## Question 3 (10pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-lodging",
   "metadata": {},
   "source": [
    "### Question 3.1\n",
    "Determine the correlation between `SPY` returns and `@business` headlines. Statistically test whether this correlation is significant or not. Comment on the results and how you may be able to improve them.\n",
    "\n",
    "Hint: The standard error for the correlation coefficient $\\rho$ is given by $\\sqrt{\\frac{1-\\rho^2}{N-2}}$ when using $N$ data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fifteen-heart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corr:           -0.009485990846686164\n",
      "Standard Error: 0.14743532229551995\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here\n",
    "print(f\"Corr:           {spy['log'].corr(spy['Sentiment'])}\")\n",
    "st_error = np.sqrt((1 - spy['log'].corr(spy['Sentiment'])**2) / (spy.shape[0] - 2))\n",
    "print(f\"Standard Error: {st_error}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71f3abcf",
   "metadata": {},
   "source": [
    "You can see that the correlation between spy and the headlines is -0.00948, which is very insignificant. The standard error is 0.14, so there is a relatively large difference between the \"population correlation\" and the sample correlation. This could be because there is only 48 samples which is technically statistically significant but it is still not a large enough sample to be confident with the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
