{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accessible-broadway",
   "metadata": {},
   "source": [
    "# FA692 Homework 4\n",
    "# Due: Wednesday, April 12 @ 11:59PM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aware-spouse",
   "metadata": {},
   "source": [
    "Name: Ryan Shea\n",
    "\n",
    "Date: 2023-04-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fundamental-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set seed of random number generator\n",
    "CWID = 10445281 #Place here your Campus wide ID number, this will personalize\n",
    "#your results, but still maintain the reproduceable nature of using seeds.\n",
    "#If you ever need to reset the seed in this assignment, use this as your seed\n",
    "#Papers that use -1 as this CWID variable will earn 0's so make sure you change\n",
    "#this value before you submit your work.\n",
    "personal = CWID % 10000\n",
    "np.random.seed(personal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-rebound",
   "metadata": {},
   "source": [
    "## Question 1 (15pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-shoulder",
   "metadata": {},
   "source": [
    "### Question 1.1\n",
    "Use the `yfinance` package (or other method of your choice) to obtain the daily adjusted close prices for the S&P500 (`SPY`) from January 1, 2023 to March 15, 2023.  You should inspect the dates for your data to make sure you are including everything appropriately.  Create a data frame (or array) of the daily log returns of this stock; you may concatenate this to your price data.  Use the `print` command to display your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ae435c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Date\n",
      "2023-03-08    0.001631\n",
      "2023-03-09   -0.018622\n",
      "2023-03-10   -0.014535\n",
      "2023-03-13   -0.001426\n",
      "2023-03-14    0.016395\n",
      "Name: Adj Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "data = yf.download('SPY', start='2023-01-01', end='2023-03-15')\n",
    "\n",
    "ret = data['Adj Close'].apply(np.log).diff().dropna()#[-2:]\n",
    "\n",
    "print(ret.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-range",
   "metadata": {},
   "source": [
    "### Question 1.2\n",
    "Scrape data from the Bloomberg `@business` Twitter account from January 1, 2023 to March 15, 2023. Save this data to a Data Frame with time stamps. Additionally, save all the collected data to a text file with time stamps. You will need to submit the text file along with your work (-5 points if not submitted).\n",
    "\n",
    "Note: Bloomberg tweets sometimes include the pipe \"|\". I recomment using tilde \"~\" as a delimiter instead.\n",
    "\n",
    "Hint: Because saving the tweets can take a long time, you can comment that code out before exporting to pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "invisible-understanding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-14 19:40:29-04:00</td>\n",
       "      <td>One Japanese fintech firm is making it compuls...</td>\n",
       "      <td>2023-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-14 19:40:29-04:00</td>\n",
       "      <td>An unlikely startup guru has emerged in Japan,...</td>\n",
       "      <td>2023-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-14 19:35:41-04:00</td>\n",
       "      <td>Some US cities are late in making financial di...</td>\n",
       "      <td>2023-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-14 19:31:07-04:00</td>\n",
       "      <td>The shipping industry is looking to rethink ev...</td>\n",
       "      <td>2023-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-14 19:25:09-04:00</td>\n",
       "      <td>A biotech wants to cut fashion waste by using ...</td>\n",
       "      <td>2023-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26809</th>\n",
       "      <td>2022-12-31 19:00:09-05:00</td>\n",
       "      <td>Toymakers have found a new group of customers:...</td>\n",
       "      <td>2022-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26810</th>\n",
       "      <td>2022-12-31 19:00:09-05:00</td>\n",
       "      <td>Belarusian hackers and dissidents determined t...</td>\n",
       "      <td>2022-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26811</th>\n",
       "      <td>2022-12-31 19:00:09-05:00</td>\n",
       "      <td>Landlords are taking out millions in loans to ...</td>\n",
       "      <td>2022-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26812</th>\n",
       "      <td>2022-12-31 19:00:09-05:00</td>\n",
       "      <td>It took a pandemic to make a dent in US inequa...</td>\n",
       "      <td>2022-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26813</th>\n",
       "      <td>2022-12-31 19:00:08-05:00</td>\n",
       "      <td>A planned train line in Mexico is billions ove...</td>\n",
       "      <td>2022-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26814 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Time  \\\n",
       "0     2023-03-14 19:40:29-04:00   \n",
       "1     2023-03-14 19:40:29-04:00   \n",
       "2     2023-03-14 19:35:41-04:00   \n",
       "3     2023-03-14 19:31:07-04:00   \n",
       "4     2023-03-14 19:25:09-04:00   \n",
       "...                         ...   \n",
       "26809 2022-12-31 19:00:09-05:00   \n",
       "26810 2022-12-31 19:00:09-05:00   \n",
       "26811 2022-12-31 19:00:09-05:00   \n",
       "26812 2022-12-31 19:00:09-05:00   \n",
       "26813 2022-12-31 19:00:08-05:00   \n",
       "\n",
       "                                                   Tweet        Date  \n",
       "0      One Japanese fintech firm is making it compuls...  2023-03-14  \n",
       "1      An unlikely startup guru has emerged in Japan,...  2023-03-14  \n",
       "2      Some US cities are late in making financial di...  2023-03-14  \n",
       "3      The shipping industry is looking to rethink ev...  2023-03-14  \n",
       "4      A biotech wants to cut fashion waste by using ...  2023-03-14  \n",
       "...                                                  ...         ...  \n",
       "26809  Toymakers have found a new group of customers:...  2022-12-31  \n",
       "26810  Belarusian hackers and dissidents determined t...  2022-12-31  \n",
       "26811  Landlords are taking out millions in loans to ...  2022-12-31  \n",
       "26812  It took a pandemic to make a dent in US inequa...  2022-12-31  \n",
       "26813  A planned train line in Mexico is billions ove...  2022-12-31  \n",
       "\n",
       "[26814 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import snscrape.modules.twitter as tw\n",
    "\n",
    "# f = open('business3.txt', 'w', encoding='utf-8')\n",
    "\n",
    "# for tweet in tw.TwitterSearchScraper(query=\"(from:business) since:2023-01-01 until:2023-03-15\").get_items():\n",
    "#     date_str = tweet.date.strftime(\"%Y-%m-%d %H:%M:%S%z\")\n",
    "#     date_str = date_str[:-2] + \":\" + date_str[-2:]\n",
    "#     #f.write(date_str + \"|\" + tweet.content + \"\\n\")\n",
    "#     f.write(date_str + \"~\" + tweet.rawContent + \"\\n\")\n",
    "# f.close()\n",
    "\n",
    "from datetime import datetime as dt\n",
    "import pytz\n",
    "\n",
    "business = []\n",
    "dates = []\n",
    "f = open('business3.txt', 'r', encoding='utf-8')\n",
    "\n",
    "for l in f:\n",
    "    line = l.split('~')\n",
    "    date_str = line[0]\n",
    "    try:\n",
    "        date_time = dt.fromisoformat(date_str)\n",
    "        date_time = date_time.astimezone(pytz.timezone(\"US/Eastern\"))\n",
    "        line[0] = date_time\n",
    "        line[1] = line[1][:-1]\n",
    "        business.append(line)\n",
    "        dates.append(date_time.date())\n",
    "    except:\n",
    "        business[-1][1] += \" \"+l[:-1]\n",
    "f.close()\n",
    "\n",
    "business = pd.DataFrame(business, columns=['Time', 'Tweet'])\n",
    "business['Date'] = dates\n",
    "\n",
    "business\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f054e182",
   "metadata": {},
   "source": [
    "### Question 1.3\n",
    "Using your favorite sentiment analyzer (e.g., `vaderSentiment`), compute the normalized positive/neutral/negative sentiment for each tweet. Find the average of all 3 polarities of sentiment for the headlines on each date that data was collected. Concatenate these 3 scores score to your data frame of log returns. Use the `print` command to display your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e5e3656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Date</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-14 19:40:29-04:00</td>\n",
       "      <td>One Japanese fintech firm is making it compuls...</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-14 19:40:29-04:00</td>\n",
       "      <td>An unlikely startup guru has emerged in Japan,...</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-14 19:35:41-04:00</td>\n",
       "      <td>Some US cities are late in making financial di...</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-14 19:31:07-04:00</td>\n",
       "      <td>The shipping industry is looking to rethink ev...</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-14 19:25:09-04:00</td>\n",
       "      <td>A biotech wants to cut fashion waste by using ...</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Time  \\\n",
       "0 2023-03-14 19:40:29-04:00   \n",
       "1 2023-03-14 19:40:29-04:00   \n",
       "2 2023-03-14 19:35:41-04:00   \n",
       "3 2023-03-14 19:31:07-04:00   \n",
       "4 2023-03-14 19:25:09-04:00   \n",
       "\n",
       "                                               Tweet        Date  Positive  \\\n",
       "0  One Japanese fintech firm is making it compuls...  2023-03-14     0.000   \n",
       "1  An unlikely startup guru has emerged in Japan,...  2023-03-14     0.000   \n",
       "2  Some US cities are late in making financial di...  2023-03-14     0.097   \n",
       "3  The shipping industry is looking to rethink ev...  2023-03-14     0.000   \n",
       "4  A biotech wants to cut fashion waste by using ...  2023-03-14     0.000   \n",
       "\n",
       "   Negative  Neutral  \n",
       "0     0.000    1.000  \n",
       "1     0.000    1.000  \n",
       "2     0.079    0.824  \n",
       "3     0.368    0.632  \n",
       "4     0.290    0.710  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "pos, neg, neu = [], [], []\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "for tweet in business['Tweet']:\n",
    "    score = analyser.polarity_scores(tweet)\n",
    "    pos.append(score['pos'])\n",
    "    neg.append(score['neg'])\n",
    "    neu.append(score['neu'])\n",
    "\n",
    "business['Positive'] = pos\n",
    "business['Negative'] = neg\n",
    "business['Neutral'] = neu\n",
    "\n",
    "business.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-tiger",
   "metadata": {},
   "source": [
    "## Question 2 (15pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-lodging",
   "metadata": {},
   "source": [
    "### Question 2.1\n",
    "Linearly regress `SPY` returns as a function of the lagged returns (2 lags).\n",
    "This should be of the form $r_{t} = \\beta_0 + \\beta_{1} r_{t-1} + \\beta_{2} r_{t-2}$.\n",
    "Evaluate the performance of this model with the mean squared error of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45e768f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape = (46, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>log_1</th>\n",
       "      <th>pos_1</th>\n",
       "      <th>neg_1</th>\n",
       "      <th>neu_1</th>\n",
       "      <th>log_2</th>\n",
       "      <th>pos_2</th>\n",
       "      <th>neg_2</th>\n",
       "      <th>neu_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-06</th>\n",
       "      <td>0.022673</td>\n",
       "      <td>0.072002</td>\n",
       "      <td>0.070873</td>\n",
       "      <td>0.857135</td>\n",
       "      <td>-0.011479</td>\n",
       "      <td>0.067030</td>\n",
       "      <td>0.071558</td>\n",
       "      <td>0.861423</td>\n",
       "      <td>0.007691</td>\n",
       "      <td>0.080386</td>\n",
       "      <td>0.076459</td>\n",
       "      <td>0.843152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-09</th>\n",
       "      <td>-0.000567</td>\n",
       "      <td>0.075860</td>\n",
       "      <td>0.057659</td>\n",
       "      <td>0.866483</td>\n",
       "      <td>0.022673</td>\n",
       "      <td>0.072002</td>\n",
       "      <td>0.070873</td>\n",
       "      <td>0.857135</td>\n",
       "      <td>-0.011479</td>\n",
       "      <td>0.067030</td>\n",
       "      <td>0.071558</td>\n",
       "      <td>0.861423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10</th>\n",
       "      <td>0.006988</td>\n",
       "      <td>0.060580</td>\n",
       "      <td>0.074328</td>\n",
       "      <td>0.865099</td>\n",
       "      <td>-0.000567</td>\n",
       "      <td>0.075860</td>\n",
       "      <td>0.057659</td>\n",
       "      <td>0.866483</td>\n",
       "      <td>0.022673</td>\n",
       "      <td>0.072002</td>\n",
       "      <td>0.070873</td>\n",
       "      <td>0.857135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-11</th>\n",
       "      <td>0.012569</td>\n",
       "      <td>0.068954</td>\n",
       "      <td>0.068449</td>\n",
       "      <td>0.862574</td>\n",
       "      <td>0.006988</td>\n",
       "      <td>0.060580</td>\n",
       "      <td>0.074328</td>\n",
       "      <td>0.865099</td>\n",
       "      <td>-0.000567</td>\n",
       "      <td>0.075860</td>\n",
       "      <td>0.057659</td>\n",
       "      <td>0.866483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-12</th>\n",
       "      <td>0.003634</td>\n",
       "      <td>0.072893</td>\n",
       "      <td>0.071808</td>\n",
       "      <td>0.855305</td>\n",
       "      <td>0.012569</td>\n",
       "      <td>0.068954</td>\n",
       "      <td>0.068449</td>\n",
       "      <td>0.862574</td>\n",
       "      <td>0.006988</td>\n",
       "      <td>0.060580</td>\n",
       "      <td>0.074328</td>\n",
       "      <td>0.865099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 log       pos       neg       neu     log_1     pos_1  \\\n",
       "Date                                                                     \n",
       "2023-01-06  0.022673  0.072002  0.070873  0.857135 -0.011479  0.067030   \n",
       "2023-01-09 -0.000567  0.075860  0.057659  0.866483  0.022673  0.072002   \n",
       "2023-01-10  0.006988  0.060580  0.074328  0.865099 -0.000567  0.075860   \n",
       "2023-01-11  0.012569  0.068954  0.068449  0.862574  0.006988  0.060580   \n",
       "2023-01-12  0.003634  0.072893  0.071808  0.855305  0.012569  0.068954   \n",
       "\n",
       "               neg_1     neu_1     log_2     pos_2     neg_2     neu_2  \n",
       "Date                                                                    \n",
       "2023-01-06  0.071558  0.861423  0.007691  0.080386  0.076459  0.843152  \n",
       "2023-01-09  0.070873  0.857135 -0.011479  0.067030  0.071558  0.861423  \n",
       "2023-01-10  0.057659  0.866483  0.022673  0.072002  0.070873  0.857135  \n",
       "2023-01-11  0.074328  0.865099 -0.000567  0.075860  0.057659  0.866483  \n",
       "2023-01-12  0.068449  0.862574  0.006988  0.060580  0.074328  0.865099  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"log\": ret})\n",
    "df['pos'] = business.pivot_table(index='Date', values='Positive', aggfunc='mean')\n",
    "df['neg'] = business.pivot_table(index='Date', values='Negative', aggfunc='mean')\n",
    "df['neu'] = business.pivot_table(index='Date', values='Neutral', aggfunc='mean')\n",
    "\n",
    "\n",
    "for i in range(1, 3):\n",
    "    df[f'log_{i}'] = df['log'].shift(i)\n",
    "    df[f'pos_{i}'] = df['pos'].shift(i)\n",
    "    df[f'neg_{i}'] = df['neg'].shift(i)\n",
    "    df[f'neu_{i}'] = df['neu'].shift(i)\n",
    "\n",
    "df = df.dropna() # lose the first 2 rows\n",
    "\n",
    "print(f\"{df.shape = }\")\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0149b46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept : 0.0007263457920817806\n",
      "\n",
      "    log_1 : 0.05614851635772608\n",
      "    log_2 : -0.12133150745716237\n",
      "\n",
      "MSE: 0.00011083584269359552\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y = df['log']\n",
    "X = df[['log_1', 'log_2']]\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n",
    "\n",
    "preds = linreg.predict(X)\n",
    "\n",
    "print(f\"Intercept : {linreg.intercept_}\", end='\\n\\n')\n",
    "\n",
    "for feat, coef in zip(X.columns, linreg.coef_):\n",
    "    print(f\"{feat:>9} : {coef}\")\n",
    "\n",
    "print()\n",
    "print(f\"MSE: {mean_squared_error(y, preds)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1513f2",
   "metadata": {},
   "source": [
    "### Question 2.2\n",
    "Linearly regress `SPY` returns as a function of the lagged sentiment scores (2 lags).\n",
    "This should be of the form $r_{t} = \\beta_0 + \\beta_{1}^{pos} s_{t-1}^{pos} + \\beta_{1}^{neu} s_{t-1}^{neu} + \\beta_{1}^{neg} s_{t-1}^{neg} + \\beta_{2}^{pos} s_{t-2}^{pos} + \\beta_{2}^{neu} s_{t-2}^{neu} + \\beta_{2}^{neg} s_{t-2}^{neg}$.\n",
    "Evaluate the performance of this model with the mean squared error of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "70aef56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept : -39.639385562760594\n",
      "\n",
      "    pos_1 : -11.529138946763046\n",
      "    pos_2 : 50.98372428142845\n",
      "    neg_1 : -10.99345559023581\n",
      "    neg_2 : 51.318176402586\n",
      "    neu_1 : -11.428918323943893\n",
      "    neu_2 : 51.02968537813942\n",
      "\n",
      "MSE: 9.73307238249023e-05\n"
     ]
    }
   ],
   "source": [
    "y = df['log']\n",
    "X = df[['pos_1', 'pos_2', 'neg_1', 'neg_2', 'neu_1', 'neu_2']]\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n",
    "\n",
    "preds = linreg.predict(X)\n",
    "\n",
    "print(f\"Intercept : {linreg.intercept_}\", end='\\n\\n')\n",
    "\n",
    "for feat, coef in zip(X.columns, linreg.coef_):\n",
    "    print(f\"{feat:>9} : {coef}\")\n",
    "\n",
    "print()\n",
    "print(f\"MSE: {mean_squared_error(y, preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cd5f26",
   "metadata": {},
   "source": [
    "### Question 2.3\n",
    "Linearly regress `SPY` returns as a function of the lagged returns and sentiment (2 lags each).\n",
    "This should be of the form $r_{t} = \\beta_0 + \\beta_{1,r} r_{t-1} + \\beta_{2,r} r_{t-2} + \\beta_{1}^{pos} s_{t-1}^{pos} + \\beta_{1}^{neu} s_{t-1}^{neu} + \\beta_{1}^{neg} s_{t-1}^{neg} + \\beta_{2}^{pos} s_{t-2}^{pos} + \\beta_{2}^{neu} s_{t-2}^{neu} + \\beta_{2}^{neg} s_{t-2}^{neg}$.\n",
    "Evaluate the performance of this model with the mean squared error of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "81e2f9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept : -43.294419357032616\n",
      "\n",
      "    log_1 : 0.06832441586556065\n",
      "    log_2 : -0.02872132228146571\n",
      "    pos_1 : -9.941652601626126\n",
      "    pos_2 : 53.08011846350946\n",
      "    neg_1 : -9.406361871438579\n",
      "    neg_2 : 53.36617138063956\n",
      "    neu_1 : -9.858793198413219\n",
      "    neu_2 : 53.11377869190214\n",
      "\n",
      "MSE: 9.679835761538497e-05\n"
     ]
    }
   ],
   "source": [
    "y = df['log']\n",
    "X = df[['log_1', 'log_2', 'pos_1', 'pos_2', 'neg_1', 'neg_2', 'neu_1', 'neu_2']]\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n",
    "\n",
    "preds = linreg.predict(X)\n",
    "\n",
    "print(f\"Intercept : {linreg.intercept_}\", end='\\n\\n')\n",
    "\n",
    "for feat, coef in zip(X.columns, linreg.coef_):\n",
    "    print(f\"{feat:>9} : {coef}\")\n",
    "\n",
    "print()\n",
    "print(f\"MSE: {mean_squared_error(y, preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c248fc",
   "metadata": {},
   "source": [
    "### Question 2.4\n",
    "Compare the performance of these 3 linear regressions. Compare also to the performance from `Homework 3` when only the `compound` sentiment score was used."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "organic-martin",
   "metadata": {},
   "source": [
    "The MSEs are lower using the different sentiment scores compared to just the compound score. It does the best when it uses all of the different features as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3131e472",
   "metadata": {},
   "source": [
    "## Question 3 (15pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2156a5c1",
   "metadata": {},
   "source": [
    "### Question 3.1\n",
    "Regress `SPY` returns with a random forest as a function of the lagged returns (2 lags).\n",
    "This should be of the form $r_{t} = f(r_{t-1} , r_{t-2})$.\n",
    "Evaluate the performance of this model with the mean squared error of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "48d75b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** |FEATURE IMPORTANCES| *****\n",
      "log_1 : 0.5194776560977129\n",
      "log_2 : 0.48052234390228704\n",
      "\n",
      "  MSE : 2.649891959962792e-05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "y = df['log']\n",
    "X = df[['log_1', 'log_2']]\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "\n",
    "preds = rf.predict(X)\n",
    "\n",
    "print(\"*\" * 5, \"|FEATURE IMPORTANCES|\", \"*\" * 5)\n",
    "for feat, imp in zip(X.columns, rf.feature_importances_):\n",
    "    print(f\"{feat:>4} : {imp}\")\n",
    "\n",
    "print()\n",
    "print(f\"  MSE : {mean_squared_error(y, preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972fef6e",
   "metadata": {},
   "source": [
    "### Question 3.2\n",
    "Regress `SPY` returns with a random forest as a function of the lagged sentiments (2 lags).\n",
    "This should be of the form $r_{t} = f(s_{t-1}^{pos},s_{t-1}^{neu},s_{t-1}^{neg} , s_{t-2}^{pos},s_{t-2}^{neu},s_{t-2}^{neg})$.\n",
    "Evaluate the performance of this model with the mean squared error of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fdc845ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** |FEATURE IMPORTANCES| *****\n",
      "pos_1 : 0.15730213951233896\n",
      "pos_2 : 0.15919690693901034\n",
      "neg_1 : 0.309288748696683\n",
      "neg_2 : 0.16301310084952395\n",
      "neu_1 : 0.11615854369598574\n",
      "neu_2 : 0.09504056030645801\n",
      "\n",
      "  MSE : 1.6281129434211215e-05\n"
     ]
    }
   ],
   "source": [
    "y = df['log']\n",
    "X = df[['pos_1', 'pos_2', 'neg_1', 'neg_2', 'neu_1', 'neu_2']]\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "\n",
    "preds = rf.predict(X)\n",
    "print(\"*\" * 5, \"|FEATURE IMPORTANCES|\", \"*\" * 5, sep=' ')\n",
    "for feat, imp in zip(X.columns, rf.feature_importances_):\n",
    "    print(f\"{feat:>4} : {imp}\")\n",
    "\n",
    "print()\n",
    "print(f\"  MSE : {mean_squared_error(y, preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edde9189",
   "metadata": {},
   "source": [
    "### Question 3.3\n",
    "Regress `SPY` returns with a random forest as a function of the lagged returns and sentiment (2 lags each).\n",
    "This should be of the form $r_{t} = f(r_{t-1} , r_{t-2} , s_{t-1}^{pos},s_{t-1}^{neu},s_{t-1}^{neg} , s_{t-2}^{pos},s_{t-2}^{neu},s_{t-2}^{neg})$.\n",
    "Evaluate the performance of this model with the mean squared error of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2b1c5b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** |FEATURE IMPORTANCES| *****\n",
      "log_1 : 0.07404880025946274\n",
      "log_2 : 0.12290223905906761\n",
      "pos_1 : 0.10456425266166411\n",
      "pos_2 : 0.12112143148872109\n",
      "neg_1 : 0.24231828025524188\n",
      "neg_2 : 0.13086798695909022\n",
      "neu_1 : 0.11788958649223147\n",
      "neu_2 : 0.08628742282452098\n",
      "\n",
      "  MSE : 1.852114314590402e-05\n"
     ]
    }
   ],
   "source": [
    "y = df['log']\n",
    "X = df[['log_1', 'log_2', 'pos_1', 'pos_2', 'neg_1', 'neg_2', 'neu_1', 'neu_2']]\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "\n",
    "preds = rf.predict(X)\n",
    "\n",
    "print(\"*\" * 5, \"|FEATURE IMPORTANCES|\", \"*\" * 5)\n",
    "for feat, imp in zip(X.columns, rf.feature_importances_):\n",
    "    print(f\"{feat:>4} : {imp}\")\n",
    "\n",
    "print()\n",
    "print(f\"  MSE : {mean_squared_error(y, preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2def2d8",
   "metadata": {},
   "source": [
    "### Question 3.4\n",
    "Compare the performance of these 3 random forest regressions. Compare also to the performance from `Homework 3` when only the `compound` sentiment score was used."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9fb2ea5f",
   "metadata": {},
   "source": [
    "The random forest regressions do better than the linear regressions across the board. This one does the best when it uses the individual sentiment scores and NO lagged returns. This is consistent with the findings from HW3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653b3544",
   "metadata": {},
   "source": [
    "## Question 4 (10pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a1b237",
   "metadata": {},
   "source": [
    "### Question 4.1\n",
    "Compare the performance of the various regressions utilized. Do you find the text data to be a useful feature in your analysis. Explain why or why not."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f75214b3",
   "metadata": {},
   "source": [
    "Text data is definitely useful in the analysis. The error is significantly lower from both HW3 and HW4 when text data is incorporated in the model. It is generally more important than the lagged returns, in terms of the error as well as the feature importances of the random forest regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
