{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as tw\n",
    "\n",
    "f = open('em.txt','w',encoding='utf-8')\n",
    "\n",
    "#Save Twitter data to external file\n",
    "#Possible outputs: url, date, content, id, username, outlinks, outlinksss, tcooutlinks, tcooutlinksss\n",
    "for tweet in tw.TwitterSearchScraper(query=\"(from:elonmusk) since:2020-08-01 until:2020-10-01\").get_items():\n",
    "    date_str = tweet.date.strftime(\"%Y-%m-%d %H:%M:%S%z\")\n",
    "    date_str = date_str[:-2] + \":\" + date_str[-2:]\n",
    "    #f.write(date_str + \"|\" + tweet.content + \"\\n\")\n",
    "    f.write(date_str + \"|\" + tweet.rawContent + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Time  \\\n",
      "0   2020-09-30 02:14:53-04:00   \n",
      "1   2020-09-30 02:13:40-04:00   \n",
      "2   2020-09-30 02:11:50-04:00   \n",
      "3   2020-09-29 14:08:27-04:00   \n",
      "4   2020-09-29 07:41:04-04:00   \n",
      "..                        ...   \n",
      "482 2020-08-02 00:49:11-04:00   \n",
      "483 2020-08-01 04:15:54-04:00   \n",
      "484 2020-08-01 02:47:18-04:00   \n",
      "485 2020-07-31 23:57:37-04:00   \n",
      "486 2020-07-31 23:51:54-04:00   \n",
      "\n",
      "                                                 Tweet        Date  \n",
      "0    @PPathole Haha true. Why do showers have such ...  2020-09-30  \n",
      "1                                          @EvaFoxU !!  2020-09-30  \n",
      "2                  @RationalEtienne @WholeMarsBlog Yes  2020-09-30  \n",
      "3    @UniverCurious @physicsJ Light is not as fast ...  2020-09-29  \n",
      "4    @SamTalksTesla Maybe we used too many magenta ...  2020-09-29  \n",
      "..                                                 ...         ...  \n",
      "482  @meier1028 @SpaceX @Space_Station @AstroBehnke...  2020-08-02  \n",
      "483  @engineeringvids The simplest solution is not ...  2020-08-01  \n",
      "484                                               🧙‍♂️  2020-08-01  \n",
      "485  @cybrtrck Absolutely. Long-lasting art is incr...  2020-07-31  \n",
      "486  This BBC article provides a sensible summary f...  2020-07-31  \n",
      "\n",
      "[487 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "import pytz\n",
    "\n",
    "#Read Twitter data into Python\n",
    "em = []\n",
    "dates = []\n",
    "f = open(\"em.txt\", \"r\", encoding=\"utf-8\")\n",
    "for l in f:\n",
    "    line = l.split(\"|\")\n",
    "    date_str = line[0]#+\"+00:00\"\n",
    "    try:\n",
    "        date_time = dt.fromisoformat(date_str)\n",
    "        date_time = date_time.astimezone(pytz.timezone(\"US/Eastern\"))\n",
    "        line[0] = date_time\n",
    "        line[1] = line[1][:-1]\n",
    "        em.append(line)\n",
    "        dates.append(date_time.date())\n",
    "    except:\n",
    "        em[-1][1] += \" \"+l[:-1]\n",
    "f.close()\n",
    "\n",
    "em = pd.DataFrame(data=em , columns=['Time','Tweet'])\n",
    "em['Date'] = dates\n",
    "#em['Date'] = em['Date'].astype(str)\n",
    "print(em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Time  \\\n",
      "0   2020-09-30 02:14:53-04:00   \n",
      "1   2020-09-30 02:13:40-04:00   \n",
      "2   2020-09-30 02:11:50-04:00   \n",
      "3   2020-09-29 14:08:27-04:00   \n",
      "4   2020-09-29 07:41:04-04:00   \n",
      "..                        ...   \n",
      "482 2020-08-02 00:49:11-04:00   \n",
      "483 2020-08-01 04:15:54-04:00   \n",
      "484 2020-08-01 02:47:18-04:00   \n",
      "485 2020-07-31 23:57:37-04:00   \n",
      "486 2020-07-31 23:51:54-04:00   \n",
      "\n",
      "                                                 Tweet        Date  Sentiment  \n",
      "0    @PPathole Haha true. Why do showers have such ...  2020-09-30     0.7263  \n",
      "1                                          @EvaFoxU !!  2020-09-30     0.0000  \n",
      "2                  @RationalEtienne @WholeMarsBlog Yes  2020-09-30     0.4019  \n",
      "3    @UniverCurious @physicsJ Light is not as fast ...  2020-09-29     0.0000  \n",
      "4    @SamTalksTesla Maybe we used too many magenta ...  2020-09-29     0.0000  \n",
      "..                                                 ...         ...        ...  \n",
      "482  @meier1028 @SpaceX @Space_Station @AstroBehnke...  2020-08-02     0.6249  \n",
      "483  @engineeringvids The simplest solution is not ...  2020-08-01     0.6801  \n",
      "484                                               🧙‍♂️  2020-08-01     0.0000  \n",
      "485  @cybrtrck Absolutely. Long-lasting art is incr...  2020-07-31    -0.4201  \n",
      "486  This BBC article provides a sensible summary f...  2020-07-31     0.0000  \n",
      "\n",
      "[487 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "#The compound score is computed by summing the valence scores of each word in the lexicon, \n",
    "#adjusted according to the rules, and then normalized to be between -1 (most extreme negative) \n",
    "#and +1 (most extreme positive). This is the most useful metric if you want a single unidimensional \n",
    "#measure of sentiment for a given sentence. Calling it a 'normalized, weighted composite score' is accurate.\n",
    "#It is also useful for researchers who would like to set standardized thresholds for classifying sentences \n",
    "#as either positive, neutral, or negative. Typical threshold values (used in the literature cited on this page) are:\n",
    "#    positive sentiment: compound score >= 0.05\n",
    "#    neutral sentiment: (compound score > -0.05) and (compound score < 0.05)\n",
    "#    negative sentiment: compound score <= -0.05\n",
    "#The pos, neu, and neg scores are ratios for proportions of text that fall in each category (so these should all \n",
    "#add up to be 1... or close to it with float operation). These are the most useful metrics if you want \n",
    "#multidimensional measures of sentiment for a given sentence.\n",
    "\n",
    "sentiment = []\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for tweet in em.Tweet:\n",
    "    vs = analyzer.polarity_scores(tweet)\n",
    "    sentiment.append(vs[\"compound\"])\n",
    "    \n",
    "em['Sentiment'] = sentiment\n",
    "print(em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "                  Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2020-08-03   96.613335  100.653999   96.292000   99.000000   99.000000   \n",
      "2020-08-04   99.667336  101.827332   97.466667   99.133331   99.133331   \n",
      "2020-08-05   99.532669   99.989334   97.887337   99.001335   99.001335   \n",
      "2020-08-06   99.388664  101.153999   98.484001   99.305336   99.305336   \n",
      "2020-08-07   99.969330   99.983330   94.334000   96.847336   96.847336   \n",
      "2020-08-10   96.533333   97.166664   92.389336   94.571335   94.571335   \n",
      "2020-08-11   93.066666   94.666664   91.000000   91.625999   91.625999   \n",
      "2020-08-12   98.000000  105.666664   95.666664  103.650665  103.650665   \n",
      "2020-08-13  107.400002  110.078667  104.484001  108.066666  108.066666   \n",
      "2020-08-14  110.999336  111.253334  108.442665  110.047333  110.047333   \n",
      "2020-08-17  111.800003  123.057335  111.522003  122.375999  122.375999   \n",
      "2020-08-18  126.599335  128.259995  123.007332  125.806000  125.806000   \n",
      "2020-08-19  124.333336  127.400002  122.747330  125.235336  125.235336   \n",
      "2020-08-20  124.045334  134.799332  123.804001  133.455338  133.455338   \n",
      "2020-08-21  136.317337  139.699326  135.003326  136.665329  136.665329   \n",
      "2020-08-24  141.751999  141.933334  128.501328  134.279999  134.279999   \n",
      "2020-08-25  131.659332  135.196671  131.199997  134.889328  134.889328   \n",
      "2020-08-26  137.333328  144.399994  136.908661  143.544662  143.544662   \n",
      "2020-08-27  145.363998  153.039993  142.833328  149.250000  149.250000   \n",
      "2020-08-28  153.007996  154.565994  145.768005  147.559998  147.559998   \n",
      "2020-08-31  148.203339  166.713333  146.703339  166.106674  166.106674   \n",
      "2020-09-01  167.380005  167.496674  156.836670  158.350006  158.350006   \n",
      "2020-09-02  159.663330  159.679993  135.039993  149.123337  149.123337   \n",
      "2020-09-03  135.743332  143.933334  134.000000  135.666672  135.666672   \n",
      "2020-09-04  134.270004  142.666672  124.006668  139.440002  139.440002   \n",
      "2020-09-08  118.666664  122.913330  109.959999  110.070000  110.070000   \n",
      "2020-09-09  118.866669  123.000000  113.836670  122.093330  122.093330   \n",
      "2020-09-10  128.736664  132.996674  120.186668  123.779999  123.779999   \n",
      "2020-09-11  127.313332  127.500000  120.166664  124.239998  124.239998   \n",
      "2020-09-14  126.983330  140.000000  124.433334  139.873337  139.873337   \n",
      "2020-09-15  145.520004  153.979996  143.566666  149.919998  149.919998   \n",
      "2020-09-16  146.623337  152.596664  145.103333  147.253326  147.253326   \n",
      "2020-09-17  138.533340  145.929993  136.000000  141.143326  141.143326   \n",
      "2020-09-18  149.313339  150.333328  142.933334  147.383331  147.383331   \n",
      "2020-09-21  151.043335  151.893326  135.690002  149.796661  149.796661   \n",
      "2020-09-22  143.199997  145.919998  139.199997  141.410004  141.410004   \n",
      "2020-09-23  135.053329  137.383331  125.293335  126.786667  126.786667   \n",
      "2020-09-24  121.266670  133.166672  117.099998  129.263336  129.263336   \n",
      "2020-09-25  131.156662  136.243332  130.433334  135.779999  135.779999   \n",
      "2020-09-28  141.539993  142.693329  138.516663  140.399994  140.399994   \n",
      "2020-09-29  138.666672  142.833328  137.199997  139.690002  139.690002   \n",
      "\n",
      "               Volume   log_ret  sentiment  \n",
      "Date                                        \n",
      "2020-08-03  132139500  0.001346   0.114467  \n",
      "2020-08-04  126225000 -0.001332   0.172318  \n",
      "2020-08-05   74217000  0.003066   0.000000  \n",
      "2020-08-06   89884500 -0.025063   0.312450  \n",
      "2020-08-07  133446000 -0.023781   0.071120  \n",
      "2020-08-10  112834500 -0.031639   0.238775  \n",
      "2020-08-11  129387000  0.123311   0.045040  \n",
      "2020-08-12  327441000  0.041722  -0.205700  \n",
      "2020-08-13  306379500  0.018162   0.190633  \n",
      "2020-08-14  188664000  0.106188   0.324227  \n",
      "2020-08-17  303634500  0.027643   0.188175  \n",
      "2020-08-18  247117500 -0.004546   0.259300  \n",
      "2020-08-19  183079500  0.063572   0.209289  \n",
      "2020-08-20  309177000  0.023768   0.208040  \n",
      "2020-08-21  322344000 -0.017608   0.000000  \n",
      "2020-08-24  300954000  0.004527   0.105544  \n",
      "2020-08-25  159883500  0.062192   0.000838  \n",
      "2020-08-26  213591000  0.038977   0.189060  \n",
      "2020-08-27  355395000 -0.011388  -0.022200  \n",
      "2020-08-28  301218000  0.118395   0.136014  \n",
      "2020-08-31  355123200 -0.047822   0.143317  \n",
      "2020-09-01  269523300 -0.060034  -0.035300  \n",
      "2020-09-02  288528300 -0.094573   0.371500  \n",
      "2020-09-03  262788300  0.027433   0.421625  \n",
      "2020-09-04  330965700 -0.236518   0.092500  \n",
      "2020-09-08  346397100  0.103669   0.080440  \n",
      "2020-09-09  238397400  0.013720   0.299300  \n",
      "2020-09-10  254791800  0.003709   0.237075  \n",
      "2020-09-11  182152500  0.118522   0.510450  \n",
      "2020-09-14  249061800  0.069365   0.240132  \n",
      "2020-09-15  291894600 -0.017947   0.312155  \n",
      "2020-09-16  216837900 -0.042379   0.187845  \n",
      "2020-09-17  230337600  0.043261   0.179080  \n",
      "2020-09-18  259220400  0.016242   0.414267  \n",
      "2020-09-21  328430400 -0.057615   0.389186  \n",
      "2020-09-22  238742400 -0.109158   0.132075  \n",
      "2020-09-23  285222600  0.019346   0.315978  \n",
      "2020-09-24  289683300  0.049184   0.000000  \n",
      "2020-09-25  201625500  0.033460   0.188495  \n",
      "2020-09-28  149158800 -0.005070   0.255828  \n",
      "2020-09-29  150657900  0.023442   0.000000  \n"
     ]
    }
   ],
   "source": [
    "import yfinance\n",
    "from datetime import datetime\n",
    "\n",
    "#Load daily Tesla Adjusted Close data and compute log returns\n",
    "tesla = yfinance.download(\"TSLA\",datetime(2020,8,1),datetime(2020,10,1)) \n",
    "tesla['log_ret'] = np.log(tesla['Adj Close'].shift(-1)) - np.log(tesla['Adj Close'])\n",
    "\n",
    "#Construct average sentiment on each day\n",
    "prev_d = datetime(2020,1,1).date()\n",
    "avg_sentiment = []\n",
    "for date in tesla.index.values:\n",
    "    d = pd.to_datetime(date).date()\n",
    "    #tesla.loc[tesla.index == date] = np.mean(em.loc[(em.Date <= d) & (em.Date > prev_d)].Sentiment)\n",
    "    avg = np.mean(em.loc[(em.Date <= d) & (em.Date > prev_d)].Sentiment)\n",
    "    if np.isnan(avg):\n",
    "        avg_sentiment.append(0)\n",
    "    else:\n",
    "        avg_sentiment.append(avg)\n",
    "    prev_d = d\n",
    "tesla['sentiment'] = avg_sentiment\n",
    "\n",
    "#Drop final row\n",
    "tesla = tesla.iloc[:-1,]\n",
    "print(tesla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03670222753640484"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find correlation between Tesla Returns and Elon Musk's Twitter account\n",
    "tesla['log_ret'].corr(tesla['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
